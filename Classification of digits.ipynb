{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import gzip\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'mnist.pkl'\n",
    "f = open(filename, 'rb')\n",
    "training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load USPS on Python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "USPSMat  = []\n",
    "USPSTar  = []\n",
    "curPath  = 'USPSdata/Numerals'\n",
    "savedImg = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    curFolderPath = curPath + '/' + str(j)\n",
    "    imgs =  os.listdir(curFolderPath)\n",
    "    for img in imgs:\n",
    "        curImg = curFolderPath + '/' + img\n",
    "        if curImg[-3:] == 'png':\n",
    "            img = Image.open(curImg,'r')\n",
    "            img = img.resize((28, 28))\n",
    "            savedImg = img\n",
    "            imgdata = (255-np.array(img.getdata()))/255\n",
    "            USPSMat.append(imgdata)\n",
    "            USPSTar.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data[0]\n",
    "Y_train = training_data[1]\n",
    "\n",
    "\n",
    "X_val = validation_data[0]\n",
    "Y_val = validation_data[1]\n",
    "\n",
    "X_test = test_data[0]\n",
    "Y_test = test_data[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='linear', C=1.0,gamma= 'auto')\n",
    "#svm = SVC(kernel='rbf', C=2.0,gamma = 1)\n",
    "#svm = SVC(kernel='linear', C=1.0,gamma= 'auto')\n",
    "#training the model\n",
    "svm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictSVM_train = []\n",
    "PredictSVM_test = []\n",
    "PredictSVM_val = []\n",
    "PredictSVM_USPS = []\n",
    "\n",
    "\n",
    "\n",
    "Y_test_pred = svm.predict(X_test)\n",
    "Y_train_pred = svm.predict(X_train)\n",
    "Y_val_pred = svm.predict(X_val)\n",
    "Y_USPS_pred = svm.predict(USPSMat)\n",
    "\n",
    "PredictSVM_test.append(Y_test_pred)\n",
    "PredictSVM_USPS.append(Y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredictSVM = np.asarray(PredictSVM).T\n",
    "PredictSVM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy of SVM on MNIST data: 0.939\n",
      "Training Accuracy of SVM: 0.97246\n",
      "Validation Accuracy of SVM: 0.9423\n",
      "Testing Accuracy of SVM on USPS data: 0.2912645632281614\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy of SVM on MNIST data:\",metrics.accuracy_score(Y_test, Y_test_pred))\n",
    "print(\"Training Accuracy of SVM:\",metrics.accuracy_score(Y_train, Y_train_pred))\n",
    "print(\"Validation Accuracy of SVM:\",metrics.accuracy_score(Y_val, Y_val_pred))\n",
    "print(\"Testing Accuracy of SVM on USPS data:\",metrics.accuracy_score(USPSTar, Y_USPS_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of testing on USPS Data:\n",
      " [[ 348   60  139   56   24   47  146   19  100   18]\n",
      " [   0  303   63   58   24   25   19   74   16   38]\n",
      " [ 476  534 1293  341  221  652  903  201  298  204]\n",
      " [ 152  275  115  898   82  240   55  706  449  588]\n",
      " [ 222  230   33    8  800   41   86   54  126  142]\n",
      " [ 345  172  221  520  215  876  264  294  692  104]\n",
      " [  74   17   55    9   10   30  462   12   82    8]\n",
      " [ 172  351   45   45  464   35   38  522   58  580]\n",
      " [  10   37   21   48   82   41    2   84  160  155]\n",
      " [ 201   21   14   17   78   13   25   34   19  163]]\n",
      "Confusion matrix of training on MNIST Data:\n",
      " [[4917    1    6    9    2   13    7    3   10    9]\n",
      " [   0 5647   15    8    8   11    1    5   37   13]\n",
      " [   1    9 4828   67    9   15    7   26   26    7]\n",
      " [   0    5   30 4893    2   87    1    6   76   18]\n",
      " [   1    0   19    1 4751    9    6   30    7   84]\n",
      " [   3    0    6   59    0 4305   16    2   56   13]\n",
      " [   4    0   14    0    4   22 4908    1    8    0]\n",
      " [   0    2   15   11    4    1    0 5030    8   90]\n",
      " [   6   12   34   38    1   39    5    6 4602   12]\n",
      " [   0    2    1   15   78    4    0   66   12 4742]]\n",
      "Confusion matrix of validation on MNIST Data:\n",
      " [[ 967    0    2    4    3   11    6    2    5    3]\n",
      " [   0 1051    6    3   10    4    3    3   18    7]\n",
      " [   5    1  940   12    6    9    7   12   11    3]\n",
      " [   1    5    9  951    0   41    0    9   21   13]\n",
      " [   2    1    9    1  935    4    7    7    2   23]\n",
      " [   3    0    2   34    1  819    6    3   24    4]\n",
      " [   7    0    6    1    5   11  935    0    2    0]\n",
      " [   1    2    6    3    1    1    0 1040    4   28]\n",
      " [   3    4    6   15    1   12    3    2  915   10]\n",
      " [   2    0    4    6   21    3    0   12    7  870]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix of testing on USPS Data:\\n\",confusion_matrix(Y_USPS_pred, USPSTar)) \n",
    "print(\"Confusion matrix of training on MNIST Data:\\n\",confusion_matrix(Y_train_pred, Y_train)) \n",
    "print(\"Confusion matrix of validation on MNIST Data:\\n\",confusion_matrix(Y_val_pred, Y_val)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=8, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=8)\n",
    "random_forest.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictRF = []\n",
    "PredictRF_USPS = []\n",
    "Y_test_pred = random_forest.predict(X_test)\n",
    "Y_train_pred = random_forest.predict(X_train)\n",
    "Y_val_pred = random_forest.predict(X_val)\n",
    "Y_USPS_pred = random_forest.predict(USPSMat)\n",
    "PredictRF.append(Y_test_pred)\n",
    "PredictRF_USPS.append(Y_USPS_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredictRF = np.asarray(PredictRF).T\n",
    "PredictRF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy of Random Forest on MNIST data: 0.9389\n",
      "Training Accuracy of Random Forest on MNIST data: 0.99818\n",
      "Validation Accuracy of Random Forest on MNIST data: 0.9456\n",
      "Testing Accuracy of Random Forest on USPS data: 0.28781439071953596\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy of Random Forest on MNIST data:\",metrics.accuracy_score(Y_test, Y_test_pred))\n",
    "print(\"Training Accuracy of Random Forest on MNIST data:\",metrics.accuracy_score(Y_train, Y_train_pred))\n",
    "print(\"Validation Accuracy of Random Forest on MNIST data:\",metrics.accuracy_score(Y_val, Y_val_pred))\n",
    "print(\"Testing Accuracy of Random Forest on USPS data:\",metrics.accuracy_score(USPSTar, Y_USPS_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of testing on USPS Data:\n",
      " [[524  93 181 153  79 207 361  89 116  78]\n",
      " [ 85 595 172  96 276 109 109 457 142 360]\n",
      " [358 263 987 245 171 214 374 425 284 350]\n",
      " [ 92 105 140 900 118 273  96 176 284 297]\n",
      " [337  97  81 100 757 100 177  76 186 233]\n",
      " [199 128 182 302 183 864 318 220 655 145]\n",
      " [121  40  59  17  48  90 437  49 104  28]\n",
      " [105 655 160 114 281  79  75 474  59 345]\n",
      " [ 28  15  24  29  29  32  21  18 129  75]\n",
      " [151   9  13  44  58  32  32  16  41  89]]\n",
      "Confusion matrix of training on MNIST Data:\n",
      " [[4932    0    1    0    1    1    0    0    1    4]\n",
      " [   0 5677    1    1    2    1    1    0    3    0]\n",
      " [   0    0 4961    8    1    1    1    3    1    1]\n",
      " [   0    0    1 5088    0    7    0    0    3    2]\n",
      " [   0    0    0    0 4852    1    1    1    1    8]\n",
      " [   0    0    0    1    0 4494    2    0    4    1]\n",
      " [   0    0    0    0    0    1 4946    0    2    0]\n",
      " [   0    0    1    0    0    0    0 5168    0    6]\n",
      " [   0    0    2    3    0    0    0    0 4827    2]\n",
      " [   0    1    1    0    3    0    0    3    0 4964]]\n",
      "Confusion matrix of validation on MNIST Data:\n",
      " [[ 976    0    5    2    2    8    7    3    2    6]\n",
      " [   0 1052    3    2    8    0    2    9   12    3]\n",
      " [   3    4  943   20    3    6    5   14   20    4]\n",
      " [   2    2    5  972    1   47    1    4   27   13]\n",
      " [   1    3    6    1  941    5    4    9    7   29]\n",
      " [   2    2    3   10    2  831    8    0   15    6]\n",
      " [   4    0    2    1    3   10  936    0    6    1]\n",
      " [   2    1    9    5    3    0    0 1036    7   21]\n",
      " [   0    0   11   13    3    7    4    1  900    9]\n",
      " [   1    0    3    4   17    1    0   14   13  869]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix of testing on USPS Data:\\n\",confusion_matrix(Y_USPS_pred, USPSTar))\n",
    "print(\"Confusion matrix of training on MNIST Data:\\n\",confusion_matrix(Y_train_pred, Y_train)) \n",
    "print(\"Confusion matrix of validation on MNIST Data:\\n\",confusion_matrix(Y_val_pred, Y_val)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vector(Y_train):\n",
    "    return np.eye(10)[Y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(training_data[0])\n",
    "Y_train = one_hot_vector(training_data[1])\n",
    "\n",
    "X_val = np.asarray(validation_data[0])\n",
    "Y_val = one_hot_vector(validation_data[1])\n",
    "\n",
    "X_test = np.asarray(test_data[0])\n",
    "Y_test = one_hot_vector(test_data[1])\n",
    "\n",
    "X_test_USPS = np.asarray(USPSMat)\n",
    "Y_test_USPS = one_hot_vector(USPSTar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=10\n",
    "image_vector_size=28*28\n",
    "image_size = 784 \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=32, activation='sigmoid', input_shape=(image_size,)))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=128, epochs=50, verbose=False,validation_split=.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_test_MNIST,accuracy_test_MNIST = model.evaluate(X_test, Y_test, verbose=False)\n",
    "loss_train,accuracy_train = model.evaluate(X_train, Y_train, verbose=False)\n",
    "loss_test_USPS,accuracy_test_USPS = model.evaluate(X_test_USPS, Y_test_USPS, verbose=False)\n",
    "loss_val,accuracy_val = model.evaluate(X_val, Y_val, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictNN = []\n",
    "PredictNN_USPS = []\n",
    "Y_test_pred = model.predict(X_test)\n",
    "Y_train_pred = model.predict(X_train)\n",
    "Y_val_pred = model.predict(X_val)\n",
    "Y_USPS_pred = model.predict(np.asarray(USPSMat))\n",
    "PredictNN.append(Y_test_pred)\n",
    "PredictNN_USPS.append(Y_USPS_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10000, 10)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredictNN = np.asarray(PredictNN)\n",
    "PredictNN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training on MNIST Data : 0.90474\n",
      "Accuracy of testing on MNIST Data : 0.9079\n",
      "Accuracy of validation on MNIST Data : 0.9136\n",
      "Accuracy of testing on USPS Data : 0.36071803589434415\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of training on MNIST Data :\",accuracy_train)\n",
    "print(\"Accuracy of testing on MNIST Data :\",accuracy_test_MNIST)\n",
    "print(\"Accuracy of validation on MNIST Data :\",accuracy_val)\n",
    "print(\"Accuracy of testing on USPS Data :\",accuracy_test_USPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data[0]\n",
    "Y_train = training_data[1]\n",
    "\n",
    "X_val = validation_data[0]\n",
    "Y_val = validation_data[1]\n",
    "\n",
    "X_test = test_data[0]\n",
    "Y_test = test_data[1]\n",
    "\n",
    "X_test_USPS = np.asarray(USPSMat)\n",
    "Y_test_USPS = USPSTar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of testing on USPS Data:\n",
      " [[ 598    3  318   61  296  167   67   69   98  323]\n",
      " [ 159  356  169  211  139  108   18  616  206   18]\n",
      " [ 216   19 1207  144   47  110   84   93   61   18]\n",
      " [  96    3  124 1257   12  262   18   98   91   39]\n",
      " [  44   82   35   39 1057  193   32  164  180  174]\n",
      " [ 197   17  184  196   36 1079  134   83   58   16]\n",
      " [ 438   11  343   84  103  208  709   27   53   24]\n",
      " [ 155  217  342  380   28  188   18  420  205   47]\n",
      " [ 151   29  155  186  122  762  124   55  356   60]\n",
      " [  43  176  175  403  141  113   12  498  264  175]]\n",
      "Confusion matrix of testing on MNIST Data:\n",
      " [[ 956    0    4    2    0    7    9    1    1    0]\n",
      " [   0 1111    1    3    0    2    4    1   13    0]\n",
      " [  11    7  905   16   16    2   15   15   36    9]\n",
      " [   3    0   22  901    1   36    3   16   20    8]\n",
      " [   1    4    4    0  911    1   12    2    5   42]\n",
      " [  15    3    7   46    9  741   20   12   31    8]\n",
      " [  18    3    6    0   16   16  893    1    5    0]\n",
      " [   4   16   29    5    7    0    0  932    3   32]\n",
      " [  10    9   10   23   12   28   14   13  839   16]\n",
      " [  14    7    5   13   45    8    0   21    6  890]]\n",
      "Confusion matrix of training on MNIST Data:\n",
      " [[4752    0   26    9   12   42   45   12   30    4]\n",
      " [   0 5488   27   20    6   32    8   19   72    6]\n",
      " [  50   58 4330   83   85   10  116   83  130   23]\n",
      " [  27   29  130 4455    5  198   30   73  106   48]\n",
      " [  11   24   25    1 4461    6   59    6   27  239]\n",
      " [  88   44   24  192   64 3780   93   26  129   66]\n",
      " [  44   21   45    2   51   78 4678    0   31    1]\n",
      " [  26   73   72   17   62   15    1 4742   14  153]\n",
      " [  35  128   83  126   36  146   42   14 4144   88]\n",
      " [  42   29   21   68  182   32    6  156   45 4407]]\n"
     ]
    }
   ],
   "source": [
    "Y_USPS_testing = []\n",
    "for i in range(len(Y_USPS_pred)):\n",
    "    Y_USPS_testing.append(np.argmax(Y_USPS_pred[i]))\n",
    "print(\"Confusion matrix of testing on USPS Data:\\n\",confusion_matrix(Y_test_USPS, Y_USPS_testing))\n",
    "\n",
    "Y_testing = []\n",
    "for i in range(len(Y_test_pred)):\n",
    "    Y_testing.append(np.argmax(Y_test_pred[i]))\n",
    "print(\"Confusion matrix of testing on MNIST Data:\\n\",confusion_matrix(Y_test, Y_testing))\n",
    "\n",
    "Y_training = []\n",
    "for i in range(len(Y_train_pred)):\n",
    "    Y_training.append(np.argmax(Y_train_pred[i]))\n",
    "print(\"Confusion matrix of training on MNIST Data:\\n\",confusion_matrix(Y_train, Y_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vector(Y_train):\n",
    "    return np.eye(10)[Y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data[0]\n",
    "Y_train = one_hot_vector(training_data[1])\n",
    "\n",
    "X_val = validation_data[0]\n",
    "Y_val = one_hot_vector(validation_data[1])\n",
    "\n",
    "X_test = test_data[0]\n",
    "Y_test = one_hot_vector(test_data[1])\n",
    "\n",
    "X_test_USPS = np.asarray(USPSMat)\n",
    "Y_test_USPS = one_hot_vector(USPSTar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(ak):\n",
    "    exp_ak = []\n",
    "    for i in range(len(ak)):\n",
    "        exp_ak.append(np.exp(ak[i]))\n",
    "    sum_ak = np.sum(np.exp(ak))\n",
    "    softmax_val = exp_ak/sum_ak\n",
    "    return softmax_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights():\n",
    "    weight = np.zeros((10,784))\n",
    "    return np.asarray(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(x,y,eta,weight):\n",
    "    for i in range(x.shape[0]):\n",
    "        ak = np.dot(weight,x[i])\n",
    "        pred_target = softmax(ak)\n",
    "        for j in range(10):\n",
    "            val = (pred_target[j] - y[i,j]) * x[i]\n",
    "            weight[j] = weight[j] - eta * val    \n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(Data, TargetData,weight):\n",
    "    ak = np.dot(Data,weight.T)\n",
    "    pred = softmax(ak)\n",
    "    pred_target = np.argmax(pred,axis =1)\n",
    "    accuracy_val = (pred_target==TargetData).sum()/len(pred_target)\n",
    "    return accuracy_val, pred_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training on MNIST data:  0.90686\n",
      "Accuracy of validation on MNIST data:  0.918\n",
      "Accuracy of testing on MNIST data:  0.9244\n",
      "Accuracy of testing on USPS data:  0.16495824791239563\n"
     ]
    }
   ],
   "source": [
    "#PredictLR_train = []\n",
    "#PredictLR_val = []\n",
    "#PredictLR_test = []\n",
    "PredictLR = []\n",
    "\n",
    "PredictLR_USPS = []\n",
    "\n",
    "weight_training = logistic_regression(np.asarray(X_train),np.asarray(Y_train),0.01,weight)\n",
    "accuracy_training, pred_train = accuracy(X_train,training_data[1],weight_training)\n",
    "PredictLR.append(pred_train)\n",
    "print(\"Accuracy of training on MNIST data: \",accuracy_training)\n",
    "\n",
    "weight_validation = logistic_regression(np.asarray(X_val),np.asarray(Y_val),0.01,weight)\n",
    "accuracy_val, pred_val = accuracy(X_val,validation_data[1],weight_validation)\n",
    "#PredictLR_val.append(pred_val)\n",
    "print(\"Accuracy of validation on MNIST data: \",accuracy_val)\n",
    "\n",
    "weight_test = logistic_regression(np.asarray(X_test),np.asarray(Y_test),0.01,weight)\n",
    "accuracy_test, pred_test = accuracy(X_test,test_data[1],weight_test)\n",
    "#PredictLR_test.append(pred_test)\n",
    "print(\"Accuracy of testing on MNIST data: \",accuracy_test)\n",
    "\n",
    "weight_test_USPS = logistic_regression(np.asarray(X_test_USPS),np.asarray(Y_test_USPS),0.01,weight)\n",
    "accuracy_test_USPS, pred_test_USPS = accuracy(X_test_USPS,USPSTar,weight_test_USPS)\n",
    "PredictLR_USPS.append(pred_test_USPS)\n",
    "print(\"Accuracy of testing on USPS data: \",accuracy_test_USPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19999"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_USPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data[0]\n",
    "Y_train = training_data[1]\n",
    "\n",
    "X_val = validation_data[0]\n",
    "Y_val = validation_data[1]\n",
    "\n",
    "X_test = test_data[0]\n",
    "Y_test = test_data[1]\n",
    "\n",
    "X_test_USPS = np.asarray(USPSMat)\n",
    "Y_test_USPS = USPSTar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of testing on USPS Data:\n",
      " [[  41    0    2    4    0   10   73    0    2 1868]\n",
      " [   0    8    5    1    3    1   62    2    2 1916]\n",
      " [   1    1  193   26    0    9  206    0   23 1540]\n",
      " [   0    0    0   25    0    3    6    0    1 1965]\n",
      " [   0    0    0    0    1    0   16    0    0 1983]\n",
      " [   6    1    7    2    0   33   86    0   18 1847]\n",
      " [   2    1   14    8    0    4  987    0   34  950]\n",
      " [   0    0    0    1    0    3    2    6    1 1987]\n",
      " [   1    0    0    0    0    0   14    0    5 1980]\n",
      " [   0    0    0    0    0    0    0    0    0 2000]]\n",
      "Confusion matrix of testing on MNIST Data:\n",
      " [[ 945    0   11    5    0    4    8    2    5    0]\n",
      " [   0 1101    6    3    1    6    1    1   16    0]\n",
      " [   3    1  958    9   11    3   12   11   21    3]\n",
      " [   0    0   22  925    0   36    0   10   12    5]\n",
      " [   0    1    8    1  915    1    8    2    8   38]\n",
      " [   6    2   16   28   10  771    9    4   38    8]\n",
      " [   7    3   10    1    6   22  903    1    5    0]\n",
      " [   1    5   26    5    8    4    0  951    2   26]\n",
      " [   3    5   11   27    9   22    5   11  875    6]\n",
      " [   7    2   12   15   24    5    0   31   13  900]]\n",
      "Confusion matrix of training on MNIST Data:\n",
      " [[4777    0    9   21    6   37   20   11   46    5]\n",
      " [   0 5513   17   33    3   31    3   16   59    3]\n",
      " [  42   73 4261  168   69   30   63   97  144   21]\n",
      " [  10   29   70 4549    2  228    7   74   81   51]\n",
      " [   9   33   22   13 4339   16   57   31   50  289]\n",
      " [  65   44   16  158   30 3974   31   22  130   36]\n",
      " [  41   18   23   13   17  174 4621    4   35    5]\n",
      " [  20   32   46   15   30   12    2 4881   18  119]\n",
      " [  30  107   34  184   16  301   33   31 4031   75]\n",
      " [  37   32    9   56   88   75    1  253   40 4397]]\n",
      "Confusion matrix of validation on MNIST Data:\n",
      " [[ 975    0    0    3    1    4    3    0    2    3]\n",
      " [   0 1047    3    4    1    3    0    1    4    1]\n",
      " [   6   22  865   28   17    7    9    9   19    8]\n",
      " [   9    4    9  933    1   47    2    1    8   16]\n",
      " [   3   11    0    1  918    0    4    2    2   42]\n",
      " [  17    5    4   36    7  802   12    2   16   14]\n",
      " [   5    5    4    0    6   19  925    0    3    0]\n",
      " [   7   14    9    9    8    0    0  981    1   61]\n",
      " [   3   37    7   42    6   43    3    4  833   31]\n",
      " [   9    6    1    9   10    4    1   16    4  901]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix of testing on USPS Data:\\n\",confusion_matrix(Y_test_USPS, pred_test_USPS))\n",
    "print(\"Confusion matrix of testing on MNIST Data:\\n\",confusion_matrix(Y_test, pred_test))\n",
    "print(\"Confusion matrix of training on MNIST Data:\\n\",confusion_matrix(Y_train, pred_train))\n",
    "print(\"Confusion matrix of validation on MNIST Data:\\n\",confusion_matrix(Y_val, pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble = []\n",
    "for i in range(10000):\n",
    "    Ensemble.append(PredictLR[i])\n",
    "    Ensemble.append(PredictSVM[i])\n",
    "    Ensemble.append(PredictRF[i])\n",
    "    Ensemble.append(PredictNN[0][i])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(Ensemble):\n",
    "    most = max(list(map(Ensemble.count, Ensemble)))\n",
    "    return list(set(filter(lambda x: Ensemble.count(x) == most, Ensemble)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9883993864059448\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Ensemble)):\n",
    "    accuracy =  max(mode(Ensemble[i].tolist()))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
